{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 12:36:13.731848: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /global/AWIsoft/proj/4.9.3/lib:/global/AWIsoft/intel//2018/intelpython2/lib\n",
      "2022-03-23 12:36:13.731879: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras import layers\n",
    "import random\n",
    "import xarray as xr\n",
    "#from keras import optimizers\n",
    "from sklearn import preprocessing\n",
    "from keras.callbacks import History\n",
    "import matplotlib.pyplot as plt\n",
    "from plain_neural_network import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_input_paths = \"/work/ollie/bpanthi/nn_interpolation/ssh_gridded_1961_001_1_m.nc\"\n",
    "target_img_paths = \"/home/ollie/ssunar/segmentation_masks/segmentation_mask_nn_1961_001_1_m.nc\"\n",
    "file_path_save = \"/work/ollie/bpanthi/NN_weights\"\n",
    "data_x = xr.open_dataset(input_input_paths)\n",
    "data_y = xr.open_dataset(target_img_paths)\n",
    "data_x = data_x.ssh.to_numpy()\n",
    "data_y = data_y.seg_mask.to_numpy()\n",
    "data_x = np.float32(data_x)\n",
    "data_y = np.float32(data_y)\n",
    "img_size = (1200, 480)\n",
    "num_classes = 3\n",
    "batch_size = 5\n",
    "epochs = 10\n",
    "total_samples = len(data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.0383692e-01 -6.9714171e-01 -6.9363987e-01 ...  9.9692100e+36\n",
      "   9.9692100e+36  9.9692100e+36]\n",
      " [-7.4457765e-01 -7.2361225e-01 -7.2052300e-01 ...  9.9692100e+36\n",
      "   9.9692100e+36  9.9692100e+36]\n",
      " [-7.6013374e-01 -7.4673313e-01 -7.4736404e-01 ...  9.9692100e+36\n",
      "   9.9692100e+36  9.9692100e+36]\n",
      " ...\n",
      " [-1.6232173e+00 -1.6178026e+00 -1.6113625e+00 ...  9.9692100e+36\n",
      "   9.9692100e+36  9.9692100e+36]\n",
      " [-1.6377305e+00 -1.6311280e+00 -1.6258327e+00 ...  9.9692100e+36\n",
      "   9.9692100e+36  9.9692100e+36]\n",
      " [-1.6477681e+00 -1.6418573e+00 -1.6364002e+00 ...  9.9692100e+36\n",
      "   9.9692100e+36  9.9692100e+36]]\n",
      "9.96921e+36\n",
      "-1.9317486\n"
     ]
    }
   ],
   "source": [
    "print(data_x[0])\n",
    "print(np.max(data_x))\n",
    "print(np.min(data_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.7038369  -0.6971417  -0.6936399  ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.74457765 -0.72361225 -0.720523   ...  0.          0.\n",
      "   0.        ]\n",
      " [-0.76013374 -0.7467331  -0.74736404 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [-1.6232173  -1.6178026  -1.6113625  ...  0.          0.\n",
      "   0.        ]\n",
      " [-1.6377305  -1.631128   -1.6258327  ...  0.          0.\n",
      "   0.        ]\n",
      " [-1.6477681  -1.6418573  -1.6364002  ...  0.          0.\n",
      "   0.        ]]\n",
      "1.0931604\n",
      "-1.9317486\n",
      "516648\n",
      "28040\n",
      "31312\n"
     ]
    }
   ],
   "source": [
    "#Work on this part\n",
    "# for i in range(total_samples):\n",
    "#     data_x[i] = (2*float(data_x[i] - np.min(data_x[i])))/(np.max(data_x[i]) - np.min(data_x[i])) - 1 \n",
    "# for i in range(total_samples):\n",
    "#     scaler = preprocessing.StandardScaler().fit(data_x[i])\n",
    "#     data_x[i] = scaler.transform(data_x[i])\n",
    "data_x[data_x>1000] = 0\n",
    "print(data_x[0])\n",
    "print(np.max(data_x))\n",
    "print(np.min(data_x))\n",
    "print(np.size(data_y[0][data_y[0]==0]))\n",
    "print(np.size(data_y[0][data_y[0]==1]))\n",
    "print(np.size(data_y[0][data_y[0]==2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input: (23, 1200, 480)\n",
      "val_input: (6, 1200, 480)\n"
     ]
    }
   ],
   "source": [
    "# Split our img paths into a training and a validation set\n",
    "split = 0.2\n",
    "train_samples = int((1-split)*total_samples)\n",
    "#same seed must be used\n",
    "random.Random(0).shuffle(data_x)\n",
    "random.Random(0).shuffle(data_y)\n",
    "train_input = data_x[0:train_samples]\n",
    "train_target = data_y[0:train_samples]\n",
    "val_input = data_x[train_samples:total_samples]\n",
    "val_target = data_y[train_samples:total_samples]\n",
    "\n",
    "print(\"train_input:\", train_input.shape)\n",
    "print(\"val_input:\", val_input.shape)\n",
    "#print(train_target[0][200])\n",
    "\n",
    "# Instantiate data Sequences for each split\n",
    "train_gen = plain_net_eddy(batch_size, img_size, train_input, train_target)\n",
    "val_gen = plain_net_eddy(batch_size, img_size, val_input, val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 12:36:19.299587: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /global/AWIsoft/proj/4.9.3/lib:/global/AWIsoft/intel//2018/intelpython2/lib\n",
      "2022-03-23 12:36:19.299614: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-23 12:36:19.299636: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (prod-0292): /proc/driver/nvidia/version does not exist\n",
      "2022-03-23 12:36:19.299871: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1200, 480, 1)]    0         \n",
      "                                                                 \n",
      " separable_conv2d (Separable  (None, 1200, 480, 16)    41        \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1200, 480, 16)    64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1200, 480, 16)     0         \n",
      "                                                                 \n",
      " separable_conv2d_1 (Separab  (None, 1200, 480, 16)    416       \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1200, 480, 16)    64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1200, 480, 16)     0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 600, 240, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " separable_conv2d_2 (Separab  (None, 600, 240, 16)     416       \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 600, 240, 16)     64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 600, 240, 16)      0         \n",
      "                                                                 \n",
      " separable_conv2d_3 (Separab  (None, 600, 240, 16)     416       \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 600, 240, 16)     64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 600, 240, 16)      0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 300, 120, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " separable_conv2d_4 (Separab  (None, 300, 120, 16)     416       \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 300, 120, 16)     64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 300, 120, 16)      0         \n",
      "                                                                 \n",
      " separable_conv2d_5 (Separab  (None, 300, 120, 16)     416       \n",
      " leConv2D)                                                       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 300, 120, 16)     64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 300, 120, 16)      0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 150, 60, 16)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 150, 60, 16)      2320      \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 150, 60, 16)      64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 150, 60, 16)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 150, 60, 16)      2320      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 150, 60, 16)      64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 150, 60, 16)       0         \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 300, 120, 16)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 300, 120, 16)     2320      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 300, 120, 16)     64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 300, 120, 16)      0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 300, 120, 16)     2320      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 300, 120, 16)     64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 300, 120, 16)      0         \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 600, 240, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 600, 240, 16)     2320      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 600, 240, 16)     64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 600, 240, 16)      0         \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 600, 240, 16)     2320      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 600, 240, 16)     64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 600, 240, 16)      0         \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 1200, 480, 16)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_transpose_6 (Conv2DT  (None, 1200, 480, 8)     1160      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 1200, 480, 8)      0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_12 (Bat  (None, 1200, 480, 8)     32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1200, 480, 3)      219       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,220\n",
      "Trainable params: 17,820\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(img_size, num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Work on this part\n",
    "from keras import backend as K\n",
    "smooth = 1.  # to avoid zero division\n",
    "\n",
    "def dice_coef_anti(y_true, y_pred):\n",
    "    y_true_anti = (y_true[:,:,1])\n",
    "    y_pred_anti = (y_pred[:,:,1])\n",
    "    intersection_anti = K.sum(y_true_anti) * (y_pred_anti)\n",
    "    return (2 * intersection_anti + smooth) / (K.sum(y_true_anti)+ K.sum(y_pred_anti) + smooth)\n",
    "\n",
    "def dice_coef_cyc(y_true, y_pred):\n",
    "    y_true_cyc = (y_true[:,:,2])\n",
    "    y_pred_cyc = (y_pred[:,:,2])\n",
    "    intersection_cyc = K.sum(y_true_cyc * y_pred_cyc)\n",
    "    return (2 * intersection_cyc + smooth) / (K.sum(y_true_cyc) + K.sum(y_pred_cyc) + smooth)\n",
    "\n",
    "def dice_coef_nn(y_true, y_pred):\n",
    "    y_true_nn = (y_true[:,:,0])\n",
    "    y_pred_nn = (y_pred[:,:,0])\n",
    "    intersection_nn = K.sum(y_true_nn * y_pred_nn)\n",
    "    return (2 * intersection_nn + smooth) / (K.sum(y_true_nn) + K.sum(y_pred_nn) + smooth)\n",
    "    \n",
    "def mean_dice_coef(y_true, y_pred):\n",
    "    return (dice_coef_anti(y_true, y_pred) + dice_coef_cyc(y_true, y_pred) + dice_coef_nn(y_true, y_pred))/3.\n",
    "\n",
    "def weighted_mean_dice_coef(y_true, y_pred):\n",
    "    return (0.36*dice_coef_anti(y_true, y_pred) + 0.62*dice_coef_cyc(y_true, y_pred) + 0.02*dice_coef_nn(y_true, y_pred))\n",
    "  \n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - weighted_mean_dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9350"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 12:36:31.871615: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /work/ollie/bpanthi/NN_weights/assets\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.9350 - val_loss: 0.9249\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.9350 - val_loss: 0.9249\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.9350 - val_loss: 0.9249\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.9350 - val_loss: 0.9249\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.9350 - val_loss: 0.9249\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9350INFO:tensorflow:Assets written to: /work/ollie/bpanthi/NN_weights/assets\n",
      "4/4 [==============================] - 13s 4s/step - loss: 0.9350 - val_loss: 0.9249\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.9350 - val_loss: 0.9249\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.9350 - val_loss: 0.9249\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 8s 2s/step - loss: 0.9350 - val_loss: 0.9249\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9350INFO:tensorflow:Assets written to: /work/ollie/bpanthi/NN_weights/assets\n",
      "4/4 [==============================] - 13s 4s/step - loss: 0.9350 - val_loss: 0.9249\n"
     ]
    }
   ],
   "source": [
    "#optimizer = keras.optimizers.Adam(clipvalue=0.5)\n",
    "model.compile(optimizer=\"adam\", loss=dice_coef_loss)\n",
    "#model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
    "#model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\")\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(file_path_save, save_best_only=True , monitor='val_loss')]\n",
    "\n",
    "# Train the model, doing validation at the end of each epoch.\n",
    "history = model.fit(train_gen, epochs=epochs, validation_data=val_gen, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.semilogy(history.history['loss'])\n",
    "plt.semilogy(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train_loss', 'val_loss'], loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1200, 480, 3)\n",
      "[0.3488051  0.35080343 0.30039155]\n",
      "[0.33585697 0.37074152 0.2934016 ]\n",
      "[0.3369317  0.37035888 0.2927094 ]\n"
     ]
    }
   ],
   "source": [
    "val_gen = plain_net_eddy(batch_size, img_size, val_input, val_target)\n",
    "val_preds = model.predict(val_gen)\n",
    "print(val_preds.shape)\n",
    "print(val_preds[0][0][0])\n",
    "print(val_preds[0][10][10])\n",
    "print(val_preds[0][100][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "575521\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAACpCAYAAADQg30VAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAMYklEQVR4nO3dUYgd53nG8f+T1Vp2nC6WmtiokqgVEKVyobazCKcuJSQpVp0Q+cagglsVXHTjgtMWgtRclNy5pYRQigvCdqs2qYVITC1MSiuUhNwEy1LiNJZkReuotbZSrYSQZlNseaW8vTgTeiqdlc7Ke3S0X/8/OMzMO9/Mfu+u/Gh2zhwrVYUkqS3vGvcEJElLz3CXpAYZ7pLUIMNdkhpkuEtSgwx3SWrQyMI9yZYkJ5LMJNk5qq8jSbpcRvGce5IJ4LvAbwKzwEvAb1fVsSX/YpKky4zqyn0zMFNV36uqt4G9wNYRfS1J0iVGFe5rgdN927NdTZJ0HawY0XkzoPZ/7v8k2QHsAJiYmPjAxYsXRzQVSWrWD6rqfYN2jOrKfRZY37e9DjjTP6CqdlfVdFVN33rrrSOahiQ17d8X2jGqcH8J2JhkQ5KbgG3A/oUG+z8vk6SlNZLbMlV1IckfAP8MTADPVNXRUXwtSdLlRnXPnar6MvDlUZ1fkrQwP6EqSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNeiq4Z7kmSTnkrzSV1ud5ECSk91yVd++XUlmkpxI8sCoJi5JWtgwV+5/C2y5pLYTOFhVG4GD3TZJNgHbgLu6Y55MMrFks5UkDeWq4V5VXwd+eEl5K7CnW98DPNRX31tV56vqFDADbF6aqUqShnWt99zvqKqzAN3y9q6+FjjdN262q0mSrqOlfkM1A2o1cGCyI8nhJIfn5+eXeBqS9P/btYb7G0nWAHTLc119FljfN24dcGbQCapqd1VNV9X05OTkNU5DkjTItYb7fmB7t74deL6vvi3JyiQbgI3AoXc2RUnSYq242oAkzwIfAt6bZBb4U+AJYF+SR4HXgYcBqupokn3AMeAC8FhVXRzR3CVJC0jVwFvi19XU1FTNzc2NexqStNwcqarpQTv8hKokNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUoKuGe5L1Sb6a5HiSo0ke7+qrkxxIcrJbruo7ZleSmSQnkjwwygYkSZcb5sr9AvDHVfXLwH3AY0k2ATuBg1W1ETjYbdPt2wbcBWwBnkwyMYrJS5IGu2q4V9XZqvpmtz4HHAfWAluBPd2wPcBD3fpWYG9Vna+qU8AMsHmJ5y1JuoJF3XNPcidwD/AicEdVnYXeXwDA7d2wtcDpvsNmu5ok6ToZOtyTvAf4EvDJqvrxlYYOqNWA8+1IcjjJ4fn5+WGnIUkawlDhnmSSXrB/oaqe68pvJFnT7V8DnOvqs8D6vsPXAWcuPWdV7a6q6aqanpycvNb5S5IGGOZpmQBPA8er6rN9u/YD27v17cDzffVtSVYm2QBsBA4t3ZQlSVezYogx9wO/A3wnyctd7U+AJ4B9SR4FXgceBqiqo0n2AcfoPWnzWFVdXOqJS5IWlqrLbodfd1NTUzU3NzfuaUjScnOkqqYH7fATqpLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDrhruSW5OcijJt5McTfKZrr46yYEkJ7vlqr5jdiWZSXIiyQOjbECSdLlhrtzPAx+uql8F7ga2JLkP2AkcrKqNwMFumySbgG3AXcAW4MkkEyOYuyRpAVcN9+r5Sbc52b0K2Ars6ep7gIe69a3A3qo6X1WngBlg81JOWpJ0ZUPdc08ykeRl4BxwoKpeBO6oqrMA3fL2bvha4HTf4bNdTZJ0nQwV7lV1saruBtYBm5P8yhWGZ9ApLhuU7EhyOMnh+fn5oSYrSRrOop6WqaofAV+jdy/9jSRrALrluW7YLLC+77B1wJkB59pdVdNVNT05Obn4mUuSFjTM0zLvS3Jbt34L8FHgVWA/sL0bth14vlvfD2xLsjLJBmAjcGiJ5y1JuoIVQ4xZA+zpnnh5F7Cvql5I8g1gX5JHgdeBhwGq6miSfcAx4ALwWFVdHM30JUmDpOqy2+HX3dTUVM3NzY17GpK03BypqulBO/yEqiQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktSgocM9yUSSbyV5odteneRAkpPdclXf2F1JZpKcSPLAKCYuSVrYYq7cHweO923vBA5W1UbgYLdNkk3ANuAuYAvwZJKJpZmuJGkYQ4V7knXAx4Cn+spbgT3d+h7gob763qo6X1WngBlg85LMVpI0lGGv3D8HfAr4aV/tjqo6C9Atb+/qa4HTfeNmu5ok6Tq5argn+ThwrqqODHnODKjVgPPuSHI4yeH5+fkhTy1JGsaKIcbcD3wiyYPAzcBUks8DbyRZU1Vnk6wBznXjZ4H1fcevA85cetKq2g3sBpiamqq33nrrHbQhSep31Sv3qtpVVeuq6k56b5R+paoeAfYD27th24Hnu/X9wLYkK5NsADYCh5Z85pKkBQ1z5b6QJ4B9SR4FXgceBqiqo0n2AceAC8BjVXXxHc9UkjS0VF12O/y6m5qaqrm5uXFPQ5KWmyNVNT1oh59QlaQGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ16IYI9wsXLox7CpLUlHfyz+wtmTfffPMnwIlxz2OE3gv8YNyTGCH7W95a7q/l3gB+caEdN0S4AycW+qeiWpDksP0tX/a3fLXc29XcELdlJElLy3CXpAbdKOG+e9wTGDH7W97sb/lqubcrSlWNew6SpCV2o1y5S5KW0NjDPcmWJCeSzCTZOe75LFaS9Um+muR4kqNJHu/qq5McSHKyW67qO2ZX1++JJA+Mb/bDSzKR5FtJXui2m+kvyW1Jvpjk1e7n+MHG+vvD7s/mK0meTXLzcu4vyTNJziV5pa+26H6SfCDJd7p9f5kk17uXkaqqsb2ACeA14P3ATcC3gU3jnNM19LAGuLdb/zngu8Am4M+BnV19J/Bn3fqmrs+VwIau/4lx9zFEn38E/APwQrfdTH/AHuD3u/WbgNta6Q9YC5wCbum29wG/t5z7A34DuBd4pa+26H6AQ8AHgQD/BPzWuHtbyte4r9w3AzNV9b2qehvYC2wd85wWparOVtU3u/U54Di9/6C20gsNuuVD3fpWYG9Vna+qU8AMve/DDSvJOuBjwFN95Sb6SzJFLyyeBqiqt6vqRzTSX2cFcEuSFcC7gTMs4/6q6uvADy8pL6qfJGuAqar6RvWS/u/6jmnCuMN9LXC6b3u2qy1LSe4E7gFeBO6oqrPQ+wsAuL0bthx7/hzwKeCnfbVW+ns/8H3gb7rbTk8luZVG+quq/wD+AngdOAv8V1X9C43012ex/azt1i+tN2Pc4T7oHteyfHwnyXuALwGfrKofX2nogNoN23OSjwPnqurIsIcMqN2w/dG7qr0X+Ouqugf4b3q/1i9kWfXX3XveSu+WxC8AtyZ55EqHDKjdsP0NYaF+WuvzMuMO91lgfd/2Onq/Mi4rSSbpBfsXquq5rvxG96sf3fJcV19uPd8PfCLJv9G7bfbhJJ+nnf5mgdmqerHb/iK9sG+lv48Cp6rq+1U1DzwH/Brt9Pczi+1ntlu/tN6McYf7S8DGJBuS3ARsA/aPeU6L0r3D/jRwvKo+27drP7C9W98OPN9X35ZkZZINwEZ6b+zckKpqV1Wtq6o76f18vlJVj9BOf/8JnE7yS13pI8AxGumP3u2Y+5K8u/uz+hF67wu10t/PLKqf7tbNXJL7uu/L7/Yd04Zxv6MLPEjvCZPXgE+Pez7XMP9fp/fr3L8CL3evB4GfBw4CJ7vl6r5jPt31e4Jl9A498CH+92mZZvoD7gYOdz/DfwRWNdbfZ4BXgVeAv6f35Miy7Q94lt77B/P0rsAfvZZ+gOnue/Ia8Fd0H+ps5eUnVCWpQeO+LSNJGgHDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBv0P6srKDL6MBoIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#seeing the prediction of first image of the validation set\n",
    "%matplotlib inline\n",
    "mask = np.argmax(val_preds[0], axis=-1)\n",
    "mask = np.expand_dims(mask, axis=-1)\n",
    "result = mask[:, :, 0]\n",
    "result = result.T\n",
    "print(np.sum(result))\n",
    "\n",
    "dct = {0: 255., 1: 0., 2: 50.}\n",
    "n = [[dct[i] for i in j] for j in result]\n",
    "\n",
    "plt.imshow(n, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eddy-tracking",
   "language": "python",
   "name": "eddy-tracking"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
